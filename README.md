# ğŸ•·ï¸ Parser API â€” powerful website data extractor

ğŸ“Œ **Repository**: [https://github.com/Vlad32-creator/Parser](https://github.com/Vlad32-creator/Parser)

## ğŸ“– Description

This is a universal website scraping API with two modes:

You can try the API at this link [https://parser-x9js.onrender.com](https://parser-x9js.onrender.com)

- **`/easePars`** â€” fast and simple. Send a JSON request and get results quickly.
- **`/mainPars`** â€” advanced and powerful. Allows full browser interaction (clicks, typing, waiting, navigation, scraping, etc).

---

## HAW TO DOWNLOAD AND RUN THE PROJECT: 

git clone https://github.com/Vlad32-creator/Parser
cd parser
npm install
npx playwright install chromium
npm start

project work ğŸ‰


## ğŸ› ï¸ Technologies Used

- [Express](https://expressjs.com/)
- [Puppeteer](https://pptr.dev/)
- [Cheerio](https://cheerio.js.org/)
- [Axios](https://axios-http.com/)

---

## ğŸš€ Quick Mode: `/easePars`

This mode is optimized for speed and simplicity. It accepts a JSON payload that describes what to extract from which elements.

### âœ… Supported attributes:

`text`, `style`, `html`, `title`, `id`, `name`, `width`, `height`, `alt`, `src`, `href`, `role`, `target`, `type`, `data`, `maxlength`, `checked`

### âœ… Request format:

```json
{
  "#elementId": "text",
  ".className": ["style", "text"],
  "url": "http://example.com"
}
Keys: valid CSS selectors (#id, .class, div, etc.)

Values: string or array of attributes to extract

url is required

ğŸ” Response format:
Returns an array of values in the exact same order you defined them in the request.
For example:

json
{
  "result": [
    "value from #element1",
    "value from .className"
  ]
}
â¡ï¸ data1 will not come before data0, even if it loads faster â€” order is preserved!

ğŸ”§ Advanced Mode: /mainPars
This mode gives you full browser automation, using plain text instructions separated by semicolons (;).

ğŸ”¹ Supported commands:
url:<page> â€” navigate to a URL

click:<selector> â€” click an element

input:[<selector>,<value>] â€” type into an input

wait:<milliseconds> â€” pause execution

data:[<selector>, <attribute>] â€” extract attribute from first matching element

alldata:[<selector>, <attribute>] â€” extract attribute from all matching elements

scrinshot â€” (coming soon)

ğŸ”¹ Notes:
The order of commands matters â€” execution happens sequentially

url can be placed anywhere in the command list

Each command must end with a semicolon ;

Use data for #ids, and alldata for .classes and tags

ğŸ” Response format:
Returns a JSON object:

json
{
  "success": {
    "data": [...],
    "screenshot": "optional/path.png"
  }
}
or in case of error:

json
{
  "error": "Something went wrong"
}
ğŸ”¹ Example:
css
url:https://example.com;
wait:2000;
click:#submitBtn;
input:[input[name="password"],value];
data:[#username,text];
alldata:[.post,html];
âš–ï¸ Comparison: Quick vs. Advanced Mode
Feature	/easePars (Quick)	/mainPars (Advanced)
ğŸ”„ Response Type	Array of values	JSON object with keys
âš¡ Speed	Very fast (1-5 sec)	Slower (up to 2â€“3 min)
ğŸ› ï¸ Flexibility	Limited	Very flexible
ğŸ§  Works with JS SPAs	âŒ React/Vue/Angular not supported	âœ… Full JS page interaction
ğŸ‘¨â€ğŸ’» Use Cases	Static content scraping	Logging in, submitting forms, deep scraping
ğŸ›‘ Limitations	No clicks, no inputs	Requires more setup and time

ğŸ“¬ How to Use the API
POST /easePars
Content-Type: application/json

Body: JSON with selectors and url

Returns: Array of values in requested order

POST /mainPars
Content-Type: text/plain

Body: text commands

Returns: JSON with success or error

ğŸ§ª Request Examples
Simple mode:
http
POST /easePars
Content-Type: application/json

{
  ".header": ["text", "style"],
  "url": "https://example.com"
}
Advanced mode:
http
POST /mainPars
Content-Type: text/plain

url:https://example.com;
wait:3000;
click:.btn-login;
input:[input[type="password"],value];
data:[#user,text];
alldata:[.comment,html];
ğŸ“ Final Words
âš ï¸ This is my first parser project â€” still a work in progress, but already very powerful!
Use the quick path for simple scraping, and advanced mode when you want full control.

ğŸ’¡ Whether you're scraping public data or automating your account login â€” this tool can handle it.

Author: Vlad32-creator
Stars â­ï¸ and feedback are always welcome!
